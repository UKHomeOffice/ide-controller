// Global imports
/* Tensor Flow JS (not used in this file) is required by @tensorflow-models/posenet library */
// eslint-disable-next-line
import * as ts from '@tensorflow/tfjs';
import * as posenet from '@tensorflow-models/posenet';

// Local imports
import { livePhotoConfig } from '../config/camera';

const {
  video,
  zoomFactor: defaultZoomFactor,
  threshold: defaulThreshold,
  imageResolution,
} = livePhotoConfig;

let net;
let keypoints;

/*
 * tfjs-models
 * https://github.com/tensorflow/tfjs-models/tree/master/posenet
 */
const loadPosenet = () =>
  posenet.load({
    architecture: 'ResNet50',
    outputStride: 32,
    multiplier: 1,
    quantBytes: 1,
    modelUrl: './model-stride32.json',
  });

/* Creates posenet singelton */
export const estimateSinglePose = async (frame) => {
  if (!net) net = await loadPosenet();
  /* parameter(imageSource, imageScaleFactor, flipHorizontal, outputStride) */
  return net.estimateSinglePose(frame, 0.5, false, 16);
};

export const getCameraDevices = async () => {
  const enumerateDevices = await navigator.mediaDevices?.enumerateDevices();

  return enumerateDevices
    ?.filter((device) => device.kind === 'videoinput')
    .map((device) => ({
      label: device.label,
      deviceId: device.deviceId,
    }));
};

const isGoodResolution = (width) => {
  const resolutionPercentage = Math.round((width / video.height) * 100);
  return resolutionPercentage > imageResolution;
};

export const isGoodPicture = (croppedImageCoordination) => {
  const isBelowThreshold = (threshold = defaulThreshold) => {
    if (!keypoints) return true;
    return !!keypoints
      .slice(0, 5)
      .find((poseItem) => poseItem.score < threshold);
  };

  const isAboveThreshold = (threshold = defaulThreshold) =>
    !isBelowThreshold(threshold);

  const isGoodRatio = ({
    sourceX,
    sourceY,
    calculatedWidth,
    calculatedHeight,
  }) => {
    const isYInsideFrame =
      sourceY >= 0 && sourceY + calculatedHeight < video.width;
    const isXInsideFrame =
      sourceX >= 0 && sourceX + calculatedWidth < video.height;
    return isYInsideFrame && isXInsideFrame;
  };

  return (
    isAboveThreshold() &&
    isGoodRatio(croppedImageCoordination) &&
    isGoodResolution(croppedImageCoordination.calculatedWidth)
  );
};

const calculateMargin = ({ leftEar, rightEar }, zoomFactor) => {
  /* 5 is an arbitrary number to divide the face into sections  */
  const faceVerticalDivisions = 5;
  let margin = ((leftEar.x - rightEar.x) / faceVerticalDivisions) * 2;
  margin *= zoomFactor;
  return margin;
};

const extractKeypointsPosition = () => ({
  nose: keypoints[0].position,
  leftEar: keypoints[3].position,
  rightEar: keypoints[4].position,
});

const calculateLiveImageCoordination = (
  { nose, leftEar, rightEar },
  zoomFactor
) => {
  const margin = calculateMargin({ leftEar, rightEar }, zoomFactor);
  /* 
  This used to be calculated dynamically like this ðŸ‘‡
  const ratio = video.height / video.width;
  But now because the image is rotated and part of it is hidden, we just calculate the visible box ratio 
  To get the dimensions go to variables.scss and look for $live-image-width & $live-image-height
  To calculate the ratio  = $live-image-height / $live-image-width
  */
  const ratio = 1.525;
  const xOneSideMargin = margin / 2;
  const xStart = Math.floor(rightEar.x) - xOneSideMargin;
  const xEnd = Math.ceil(leftEar.x) + xOneSideMargin;
  const sWidth = xEnd - xStart;
  const sHeight = sWidth * ratio;
  const yStart = Math.floor(nose.y) - sHeight / 1.7;

  return {
    sourceX: xStart,
    sourceY: yStart,
    calculatedWidth: sWidth,
    calculatedHeight: sHeight,
  };
};

const calculateCoordination = ({ nose, leftEar, rightEar }, zoomFactor) => {
  const margin = calculateMargin({ leftEar, rightEar }, zoomFactor);
  const ratio = 663.812 / 440.906;
  const xStart = Math.floor(rightEar.x) - margin / 2;
  const xEnd = Math.ceil(leftEar.x) + margin / 2;
  const sWidth = xEnd - xStart;
  const sHeight = sWidth * ratio;
  const yStart = Math.floor(nose.y) - sHeight / 1.7;

  return {
    sourceX: xStart,
    sourceY: yStart,
    calculatedWidth: sWidth,
    calculatedHeight: sHeight,
  };
};

export const getCroppedImageCoordination = async (
  frame,
  zoomFactor = defaultZoomFactor,
  rotate = false
) => {
  keypoints = (await estimateSinglePose(frame)).keypoints;
  const keypointsPosition = extractKeypointsPosition();
  return rotate
    ? calculateLiveImageCoordination(keypointsPosition, zoomFactor)
    : calculateCoordination(keypointsPosition, zoomFactor);
};

export default {};
